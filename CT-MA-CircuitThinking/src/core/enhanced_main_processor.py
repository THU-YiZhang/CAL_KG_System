"""
Enhanced Main Processor for CT-MA System.

å¢å¼ºä¸»å¤„ç†å™¨ï¼Œæ•´åˆé—®é¢˜è®¾è®¡ã€CoTç”Ÿæˆã€ä¸“å®¶æ”¹è¿›å’Œç»Ÿä¸€JSONè¾“å‡º
"""

import asyncio
import time
from typing import Dict, List, Any, Optional
from pathlib import Path
from datetime import datetime

from ..utils.logger import LoggerMixin
from ..utils.config_manager import ConfigManager
from ..core.kg_loader import KGLoader
from ..visualization.mermaid_extractor import MermaidKGExtractor
from ..agents.enhanced_logic_agent import EnhancedLogicAgent
from ..agents.enhanced_think_team import EnhancedThinkTeam
from ..agents.enhanced_answer_agent import EnhancedAnswerAgent
from ..agents.expert_improvement_team import ExpertImprovementTeam
from ..question_design.kg_based_question_designer import KGBasedQuestionDesigner, QuestionFilterAndSelector
from ..data_integration.unified_json_generator import UnifiedJSONGenerator


class EnhancedMainProcessor(LoggerMixin):
    """å¢å¼ºä¸»å¤„ç†å™¨"""
    
    def __init__(self, config: ConfigManager):
        """Initialize enhanced main processor."""
        self.config = config
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.kg_loader = KGLoader(config)
        self.mermaid_extractor = MermaidKGExtractor(config)
        self.question_designer = KGBasedQuestionDesigner(config)
        self.question_filter = QuestionFilterAndSelector(config)
        self.logic_agent = EnhancedLogicAgent(config)
        self.think_team = EnhancedThinkTeam(config)
        self.answer_agent = EnhancedAnswerAgent(config)
        self.expert_team = ExpertImprovementTeam(config)
        self.json_generator = UnifiedJSONGenerator(config)
        
        # å¹¶å‘æ§åˆ¶
        self.semaphore = asyncio.Semaphore(config.get('concurrent.max_calls', 8))
        
    async def process_applications(
        self,
        max_applications: int = 3,
        questions_per_application: int = 5,
        output_dir: Optional[Path] = None
    ) -> Dict[str, Any]:
        """å¤„ç†å¤šä¸ªç”µè·¯åº”ç”¨"""
        
        if output_dir is None:
            output_dir = Path("output")
        
        self.logger.info(f"å¼€å§‹å¤„ç† {max_applications} ä¸ªç”µè·¯åº”ç”¨ï¼Œæ¯ä¸ªåº”ç”¨ {questions_per_application} ä¸ªé—®é¢˜")
        
        start_time = time.time()
        
        try:
            # 1. åŠ è½½çŸ¥è¯†å›¾è°±
            self.logger.info("ğŸ”„ æ­¥éª¤1: åŠ è½½ç»Ÿä¸€çŸ¥è¯†å›¾è°±...")
            kg_data = await self.kg_loader.load_knowledge_graph()
            kg_load_time = time.time() - start_time
            self.logger.info(f"âœ… çŸ¥è¯†å›¾è°±åŠ è½½å®Œæˆï¼š{len(kg_data['nodes'])} ä¸ªèŠ‚ç‚¹ï¼Œ{len(kg_data['edges'])} æ¡è¾¹ï¼Œè€—æ—¶ {kg_load_time:.2f} ç§’")
            
            # 2. æå–Mermaidå›¾è°±
            self.logger.info("ğŸ”„ æ­¥éª¤2: æå–ç”µè·¯åº”ç”¨çŸ¥è¯†å›¾è°±...")
            extract_start = time.time()
            mermaid_graphs = self.mermaid_extractor.extract_circuit_application_graphs(kg_data)
            extract_time = time.time() - extract_start
            self.logger.info(f"âœ… å›¾è°±æå–å®Œæˆï¼š{len(mermaid_graphs)} ä¸ªåº”ç”¨å›¾è°±ï¼Œè€—æ—¶ {extract_time:.2f} ç§’")
            
            # 3. é€‰æ‹©è¦å¤„ç†çš„åº”ç”¨
            selected_graphs = mermaid_graphs[:max_applications]
            self.logger.info(f"ğŸ“‹ é€‰æ‹©å¤„ç†å‰ {len(selected_graphs)} ä¸ªåº”ç”¨")
            
            # 4. å¹¶å‘å¤„ç†æ¯ä¸ªåº”ç”¨
            self.logger.info("ğŸ”„ æ­¥éª¤3: å¹¶å‘å¤„ç†å„åº”ç”¨...")
            process_start = time.time()
            
            tasks = [
                self._process_single_application(graph_data, questions_per_application, i+1, len(selected_graphs))
                for i, graph_data in enumerate(selected_graphs)
            ]
            
            application_results = await asyncio.gather(*tasks, return_exceptions=True)
            process_time = time.time() - process_start
            
            # 5. å¤„ç†ç»“æœå’Œå¼‚å¸¸
            successful_results = []
            failed_results = []
            
            for i, result in enumerate(application_results):
                if isinstance(result, Exception):
                    app_name = selected_graphs[i].get('application_label', f'åº”ç”¨{i+1}')
                    self.logger.error(f"âŒ åº”ç”¨ {app_name} å¤„ç†å¤±è´¥ï¼š{result}")
                    failed_results.append({'application': app_name, 'error': str(result)})
                else:
                    successful_results.append(result)
            
            self.logger.info(f"âœ… åº”ç”¨å¤„ç†å®Œæˆï¼šæˆåŠŸ {len(successful_results)} ä¸ªï¼Œå¤±è´¥ {len(failed_results)} ä¸ªï¼Œè€—æ—¶ {process_time:.2f} ç§’")
            
            # 6. ç”Ÿæˆç»Ÿä¸€JSONæ•°æ®
            self.logger.info("ğŸ”„ æ­¥éª¤4: ç”Ÿæˆç»Ÿä¸€JSONæ•°æ®...")
            json_start = time.time()
            
            unified_records = []
            for result in successful_results:
                if result.get('success', False):
                    unified_record = self.json_generator.generate_unified_json_record(
                        application_info=result['application_info'],
                        mermaid_kg_data=result['mermaid_data'],
                        questions=result['questions'],
                        cot_results=result['cot_results'],
                        expert_improvements=result['expert_improvements'],
                        processing_metrics=result['processing_metrics']
                    )
                    unified_records.append(unified_record)
            
            # ä¿å­˜ç»Ÿä¸€JSONæ–‡ä»¶
            output_file = self.json_generator.save_unified_json(unified_records, output_dir)
            json_time = time.time() - json_start
            
            self.logger.info(f"âœ… ç»Ÿä¸€JSONæ•°æ®ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶ {json_time:.2f} ç§’")
            
            # 7. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            total_time = time.time() - start_time
            
            final_report = {
                'success': True,
                'processing_summary': {
                    'total_applications_requested': max_applications,
                    'applications_processed': len(successful_results),
                    'applications_failed': len(failed_results),
                    'total_questions_generated': sum(len(r.get('questions', [])) for r in successful_results),
                    'total_cot_generated': sum(len(r.get('cot_results', [])) for r in successful_results),
                    'output_file': str(output_file),
                    'processing_times': {
                        'kg_loading': kg_load_time,
                        'graph_extraction': extract_time,
                        'application_processing': process_time,
                        'json_generation': json_time,
                        'total_time': total_time
                    }
                },
                'failed_applications': failed_results,
                'output_file_path': str(output_file)
            }
            
            self.logger.info(f"ğŸ‰ å…¨éƒ¨å¤„ç†å®Œæˆï¼æ€»è€—æ—¶ {total_time:.2f} ç§’")
            self.logger.info(f"ğŸ“„ ç»“æœæ–‡ä»¶ï¼š{output_file}")
            
            return final_report
            
        except Exception as e:
            self.logger.error(f"âŒ ä¸»å¤„ç†æµç¨‹å¤±è´¥ï¼š{e}")
            import traceback
            traceback.print_exc()
            
            return {
                'success': False,
                'error': str(e),
                'processing_time': time.time() - start_time
            }
    
    async def _process_single_application(
        self, 
        graph_data: Dict[str, Any], 
        questions_per_application: int,
        current_index: int,
        total_count: int
    ) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªç”µè·¯åº”ç”¨"""
        
        async with self.semaphore:
            app_name = graph_data.get('application_label', 'Unknown')
            self.logger.info(f"ğŸ”„ å¤„ç†åº”ç”¨ {current_index}/{total_count}ï¼š{app_name}")
            
            app_start_time = time.time()
            
            try:
                # 1. ç”Ÿæˆå¯è¯»æè¿°
                readable_description = self.mermaid_extractor.generate_readable_text_description(graph_data)
                
                # 2. åŸºäºçŸ¥è¯†å›¾è°±è®¾è®¡é—®é¢˜
                question_start = time.time()
                question_result = await self.question_designer.execute({
                    'subgraph': graph_data,
                    'readable_description': readable_description,
                    'question_count': questions_per_application * 2  # è®¾è®¡æ›´å¤šé—®é¢˜ç”¨äºç­›é€‰
                })
                
                # ç­›é€‰æœ€ä½³é—®é¢˜
                designed_questions = question_result.get('designed_questions', [])
                selected_questions = self.question_filter.filter_and_select_questions(
                    designed_questions, 
                    questions_per_application
                )
                question_time = time.time() - question_start
                
                self.logger.info(f"  ğŸ“ é—®é¢˜è®¾è®¡å®Œæˆï¼šè®¾è®¡ {len(designed_questions)} ä¸ªï¼Œç­›é€‰ {len(selected_questions)} ä¸ªï¼Œè€—æ—¶ {question_time:.2f} ç§’")
                
                # 3. ä¸ºæ¯ä¸ªé—®é¢˜ç”ŸæˆCoT
                cot_start = time.time()
                cot_results = []
                
                for question in selected_questions:
                    cot_result = await self._generate_cot_for_question(
                        question, graph_data, readable_description
                    )
                    cot_results.append(cot_result)
                
                cot_time = time.time() - cot_start
                successful_cot = len([r for r in cot_results if r.get('success', False)])
                self.logger.info(f"  ğŸ§  CoTç”Ÿæˆå®Œæˆï¼š{successful_cot}/{len(selected_questions)} ä¸ªæˆåŠŸï¼Œè€—æ—¶ {cot_time:.2f} ç§’")
                
                # 4. ä¸“å®¶å›¢é˜Ÿæ”¹è¿›
                expert_start = time.time()
                expert_improvements = []
                
                for cot_result in cot_results:
                    if cot_result.get('success', False):
                        improvement_result = await self.expert_team.execute({
                            'question': cot_result['question_text'],
                            'logic': cot_result['logic'],
                            'think': cot_result['think'],
                            'answer': cot_result['answer'],
                            'question_id': cot_result['question_id']
                        })
                        expert_improvements.extend(improvement_result.get('improvements', []))
                
                expert_time = time.time() - expert_start
                self.logger.info(f"  ğŸ‘¥ ä¸“å®¶æ”¹è¿›å®Œæˆï¼š{len(expert_improvements)} æ¬¡æ”¹è¿›ï¼Œè€—æ—¶ {expert_time:.2f} ç§’")
                
                # 5. æ„å»ºç»“æœ
                app_total_time = time.time() - app_start_time
                
                result = {
                    'success': True,
                    'application_info': {
                        'name': app_name,
                        'id': graph_data.get('application_id', ''),
                        'description': readable_description[:200] + '...' if len(readable_description) > 200 else readable_description,
                        'keywords': []  # å¯ä»¥ä»å›¾è°±ä¸­æå–
                    },
                    'mermaid_data': graph_data,
                    'questions': selected_questions,
                    'cot_results': cot_results,
                    'expert_improvements': expert_improvements,
                    'processing_metrics': {
                        'question_design_time': question_time,
                        'cot_generation_time': cot_time,
                        'expert_improvement_time': expert_time,
                        'total_time': app_total_time
                    }
                }
                
                self.logger.info(f"  âœ… åº”ç”¨ {app_name} å¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶ {app_total_time:.2f} ç§’")
                
                return result
                
            except Exception as e:
                self.logger.error(f"  âŒ åº”ç”¨ {app_name} å¤„ç†å¤±è´¥ï¼š{e}")
                return {
                    'success': False,
                    'application_name': app_name,
                    'error': str(e),
                    'processing_time': time.time() - app_start_time
                }
    
    async def _generate_cot_for_question(
        self, 
        question: Dict[str, Any], 
        graph_data: Dict[str, Any], 
        readable_description: str
    ) -> Dict[str, Any]:
        """ä¸ºå•ä¸ªé—®é¢˜ç”ŸæˆCoT"""
        
        question_id = question.get('question_id', '')
        question_text = question.get('question_text', '')
        
        try:
            # 1. ç”ŸæˆLogic
            logic_start = time.time()
            logic_result = await self.logic_agent.execute({
                'subgraph': graph_data,
                'readable_description': readable_description,
                'question': question_text
            })
            logic_time = time.time() - logic_start
            
            if not logic_result.get('success', False):
                return {
                    'question_id': question_id,
                    'question_text': question_text,
                    'success': False,
                    'error': f"Logicç”Ÿæˆå¤±è´¥ï¼š{logic_result.get('error', 'Unknown error')}"
                }
            
            logic = logic_result.get('logic', '')
            
            # 2. ç”ŸæˆThink
            think_start = time.time()
            think_result = await self.think_team.execute({
                'logic': logic,
                'question': question_text,
                'subgraph': graph_data
            })
            think_time = time.time() - think_start
            
            if not think_result.get('success', False):
                return {
                    'question_id': question_id,
                    'question_text': question_text,
                    'logic': logic,
                    'success': False,
                    'error': f"Thinkç”Ÿæˆå¤±è´¥ï¼š{think_result.get('error', 'Unknown error')}"
                }
            
            think = think_result.get('think', '')
            
            # 3. ç”ŸæˆAnswer
            answer_start = time.time()
            answer_result = await self.answer_agent.execute({
                'logic': logic,
                'think': think,
                'question': question_text
            })
            answer_time = time.time() - answer_start
            
            if not answer_result.get('success', False):
                return {
                    'question_id': question_id,
                    'question_text': question_text,
                    'logic': logic,
                    'think': think,
                    'success': False,
                    'error': f"Answerç”Ÿæˆå¤±è´¥ï¼š{answer_result.get('error', 'Unknown error')}"
                }
            
            answer = answer_result.get('answer', '')
            
            return {
                'question_id': question_id,
                'question_text': question_text,
                'logic': logic,
                'think': think,
                'answer': answer,
                'success': True,
                'logic_time': logic_time,
                'think_time': think_time,
                'answer_time': answer_time,
                'total_time': logic_time + think_time + answer_time,
                'rag_evidence': think_result.get('rag_evidence', []),
                'rag_quality_score': think_result.get('rag_quality_score', 0)
            }
            
        except Exception as e:
            return {
                'question_id': question_id,
                'question_text': question_text,
                'success': False,
                'error': str(e)
            }
